{"text": " So I think we're going to live in a world where there are going to be hundreds of millions of billions of different AI agents, eventually probably more AI agents than there are people in the world. From generative AI to what's known as agentic AIs. That agent force is what he's calling it. Agent force will be... AI agents has become the talk of the town and today I'm going to explain this concept in a way that even a high school student can understand it easily. Let's start with analogy and then we will go into technical details. Let's say you have a restaurant you hire two waiters, Mohan and Madhu. Mohan is intelligent and accurate. He will go to a customer who is coming to a restaurant and then he will offer the food menu. The customer will order few things. He will accurately note it down and deliver it in a nice manner. While Mohan is accurate in his work, he doesn't provide extra suggestions or recommendation. Madhu on the other hand is also intelligent and accurate, but he provides extra suggestions. For example, if a customer is ordering naan and Indian curry and if the weather is cold outside, a Madhu will say, why don't you order this hot tomato soup? The weather is cold outside and it will really go well with this dish. If the customer is coming again and again, Madhu will recognize their favorite dish and they will say, oh, last time you order Hara Bara Kebab, would you like to repeat that? So this way Madhu is going one step ahead. He's an independent thinker. He's providing these suggestions and he's autonomous in the way that he works. The first waiter Mohan on the other hand is not autonomous. He will do things as directed. In this analogy, the second waiter Madhu is an AI agent. The first waiter Mohan is a traditional AI system. Okay. So both are AI system. The first one is a traditional AI system. The second one is an AI system, which is based on AI agent. Here I have the example of a regular chat board where you ask questions such as what are your store hours? What pizza options do you have? You can also place an order. This kind of chat board can be easily built using frameworks such as dialog flow, Rasa. There are LLM based frameworks to AI agent based chat board system. On the other hand, will be autonomous in certain decision making. For example, you're visiting this pizza store Pandeji pizza store every Friday evening and you're ordering same large veggie pizza with olive topping. This chat board can learn from it. And when you say I want to place an order, it can look at your history and say, Hey, would you like to reorder your usual large pizza? You'll say yes. It will also have awareness about environment. So here it is saying, Hey, it's cold out there. Do you want to add hot chocolate? So all these suggestions that it is providing, they are not coded into your Python program. This is something that this agent is coming up on its own. It can also check weather and traffic condition and say, Hey, you want to order a pizza, but there is a snowstorm and deliveries might be delayed. This is like human. If there is a human, he will be aware about environment weather, all of that, and they will provide extra suggestions. Now let's understand a little more in technical details, how regular AI chat board works. Whenever you are asking any question, it will first identify an intent. So let's say in my chat board, I have three type of intent, general inquiry, placing order refund. Based on the question, it will say, Hey, this is a general inquiry intent. Now you will be like, okay, you can just do exit sentence matching. And you can say, this is a software program varies AI, but this is an AI based system because your question might be different instead of saying, what are your store hours? You can say, Hey, can you tell me when the store is open? So there is no exit word to word matching. These two sentences are different, but the meaning is same. So if you're using any LLM, such as GPT, or cloud, etc, it will be able to match all these sentences, okay? You can just say that, hey, LLM, if someone asks questions, which is what are your store hours, or a similar question in English language, then the intent is general inquiry. Once you tell that to LLM, next time, if a person asks questions differently, then also it will be able to match that intent. A second question you can ask is, can you place an order with large veggie pizza or leaven spinach topping, it will match the intent, say place order, not only that it will extract the meaningful information, which is what is my order size, my type toppings, etc. And it will call an appropriate code or API or let's say Python function, which you can run and place the order and insert a record in database and so on. So this is a traditional chatbot. This doesn't use any agent, etc. If you want to learn more in detail, I have this free YouTube video where I build the exact same chatbot using dialog flow framework. Now let's see how AI agent chatbot will work. So first of all, AI agent chatbot will have exact same capabilities as the regular chatbot. But in addition, it will have extra capabilities. So when you give a sentence, it will be able to identify the intent, it will extract the information, call the Python function API and so on. But in addition, it will have access to something called tools. Now when I say tools, let's say weather API is one type of tool. So it will go check weather API and say there is a snowstorm and you know, there is a traffic deliveries are delayed, then it will give you this kind of response. It will say, hey, due to snowstorm deliveries might be delayed. It may have access to another tool such as a database. Database contains all the past records from the same customer. Now you can figure out that this customer is ordering same pizza every Friday at 7 p.m. or evening. Then you will say, hey, would you like to reorder your usual large pizza with olive toppings? So see, this is intelligent and autonomous in your code. You're not return that when person says place an order, you should give this as a response. OK, in your code, you have not written that, but the agent figures this thing out on his own and provides suggestion. It can have access to web search. It can have access to a variety of APIs. So these tools are something that you can define when you are writing code for agent. So agent solution is something for which you have to write code, obviously, but you don't type all this instruction that if person places an order in a person has a same history Friday 7 p.m. large veggie, then just repeat that. OK, you are just providing all these tools, everything. And this suggestion is something that this agent comes up on its own. I give an example of an AI chat board, but there are a variety of solutions that can be a recommendation engine that can be a document search. You know, you can build a variety of solutions. Chat board is just one category of AI solutions to summarize. The main thing in AI agent is autonomy, independent thinking. Obviously, there will be some limitations on autonomy. Your chat board cannot say, hey, I will place your order for free and your family and friends. I will give everything for free. That kind of autonomy you can't give to the agents. So when you are building agents by writing code, you will have some kind of control over it. If you cannot control the AI agent will be autonomous. It's like your dog and you have a lease, right? So dog can roam around, but you have a lease. So the area where it can go, that area is limited, right? Let's say you have a two meter long lease or the string, you know, that you tie at dog's neck. The dog can roam around in that two meter radius. So it is autonomous. But on top of that, there is some control that you're imposing. There are frameworks such as Langraph, Microsoft autogen, crew AI, etc, that you can use to build AI agents. I'm going to be publishing more videos on AI agents in the coming time. So please keep an eye. And if you like this video, then please give it a thumbs up, share it with your friends. If you have any comments, there is a comment box below.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.98, "text": " So I think we're going to live in a world where there are going to be hundreds of millions", "tokens": [50363, 1406, 314, 892, 356, 821, 1016, 284, 2107, 287, 257, 995, 810, 612, 389, 1016, 284, 307, 5179, 286, 5242, 50512], "temperature": 0.0, "avg_logprob": -0.17314966987161076, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.007181928027421236}, {"id": 1, "seek": 0, "start": 2.98, "end": 7.8, "text": " of billions of different AI agents, eventually probably more AI agents than there are people", "tokens": [50512, 286, 13188, 286, 1180, 9552, 6554, 11, 4191, 2192, 517, 9552, 6554, 621, 612, 389, 661, 50753], "temperature": 0.0, "avg_logprob": -0.17314966987161076, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.007181928027421236}, {"id": 2, "seek": 0, "start": 7.8, "end": 8.8, "text": " in the world.", "tokens": [50753, 287, 262, 995, 13, 50803], "temperature": 0.0, "avg_logprob": -0.17314966987161076, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.007181928027421236}, {"id": 3, "seek": 0, "start": 8.8, "end": 13.44, "text": " From generative AI to what's known as agentic AIs.", "tokens": [50803, 3574, 1152, 876, 9552, 284, 644, 338, 1900, 355, 5797, 291, 317, 3792, 13, 51035], "temperature": 0.0, "avg_logprob": -0.17314966987161076, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.007181928027421236}, {"id": 4, "seek": 0, "start": 13.44, "end": 15.96, "text": " That agent force is what he's calling it.", "tokens": [51035, 1320, 5797, 2700, 318, 644, 339, 338, 4585, 340, 13, 51161], "temperature": 0.0, "avg_logprob": -0.17314966987161076, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.007181928027421236}, {"id": 5, "seek": 0, "start": 15.96, "end": 16.96, "text": " Agent force will be...", "tokens": [51161, 15906, 2700, 481, 307, 986, 51211], "temperature": 0.0, "avg_logprob": -0.17314966987161076, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.007181928027421236}, {"id": 6, "seek": 0, "start": 16.96, "end": 22.6, "text": " AI agents has become the talk of the town and today I'm going to explain this concept", "tokens": [51211, 9552, 6554, 468, 1716, 262, 1561, 286, 262, 3240, 290, 1909, 314, 1101, 1016, 284, 4727, 428, 3721, 51493], "temperature": 0.0, "avg_logprob": -0.17314966987161076, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.007181928027421236}, {"id": 7, "seek": 0, "start": 22.6, "end": 26.6, "text": " in a way that even a high school student can understand it easily.", "tokens": [51493, 287, 257, 835, 326, 772, 257, 1029, 1524, 3710, 460, 1833, 340, 3538, 13, 51693], "temperature": 0.0, "avg_logprob": -0.17314966987161076, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.007181928027421236}, {"id": 8, "seek": 2660, "start": 26.6, "end": 30.6, "text": " Let's start with analogy and then we will go into technical details.", "tokens": [50363, 3914, 338, 923, 351, 23970, 290, 788, 356, 481, 467, 656, 6276, 3307, 13, 50563], "temperature": 0.0, "avg_logprob": -0.21226535409183825, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.1457294523715973}, {"id": 9, "seek": 2660, "start": 30.6, "end": 35.04, "text": " Let's say you have a restaurant you hire two waiters, Mohan and Madhu.", "tokens": [50563, 3914, 338, 910, 345, 423, 257, 7072, 345, 11078, 734, 4043, 364, 11, 9719, 272, 290, 4627, 13415, 13, 50785], "temperature": 0.0, "avg_logprob": -0.21226535409183825, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.1457294523715973}, {"id": 10, "seek": 2660, "start": 35.04, "end": 36.6, "text": " Mohan is intelligent and accurate.", "tokens": [50785, 9719, 272, 318, 12661, 290, 7187, 13, 50863], "temperature": 0.0, "avg_logprob": -0.21226535409183825, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.1457294523715973}, {"id": 11, "seek": 2660, "start": 36.6, "end": 41.64, "text": " He will go to a customer who is coming to a restaurant and then he will offer the food", "tokens": [50863, 679, 481, 467, 284, 257, 6491, 508, 318, 2406, 284, 257, 7072, 290, 788, 339, 481, 2897, 262, 2057, 51115], "temperature": 0.0, "avg_logprob": -0.21226535409183825, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.1457294523715973}, {"id": 12, "seek": 2660, "start": 41.64, "end": 42.64, "text": " menu.", "tokens": [51115, 6859, 13, 51165], "temperature": 0.0, "avg_logprob": -0.21226535409183825, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.1457294523715973}, {"id": 13, "seek": 2660, "start": 42.64, "end": 44.68000000000001, "text": " The customer will order few things.", "tokens": [51165, 383, 6491, 481, 1502, 1178, 1243, 13, 51267], "temperature": 0.0, "avg_logprob": -0.21226535409183825, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.1457294523715973}, {"id": 14, "seek": 2660, "start": 44.68000000000001, "end": 49.0, "text": " He will accurately note it down and deliver it in a nice manner.", "tokens": [51267, 679, 481, 14351, 3465, 340, 866, 290, 5203, 340, 287, 257, 3621, 5642, 13, 51483], "temperature": 0.0, "avg_logprob": -0.21226535409183825, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.1457294523715973}, {"id": 15, "seek": 2660, "start": 49.0, "end": 55.2, "text": " While Mohan is accurate in his work, he doesn't provide extra suggestions or recommendation.", "tokens": [51483, 2893, 9719, 272, 318, 7187, 287, 465, 670, 11, 339, 1595, 470, 2148, 3131, 11776, 393, 15602, 13, 51793], "temperature": 0.0, "avg_logprob": -0.21226535409183825, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.1457294523715973}, {"id": 16, "seek": 5520, "start": 55.2, "end": 61.040000000000006, "text": " Madhu on the other hand is also intelligent and accurate, but he provides extra suggestions.", "tokens": [50363, 4627, 13415, 319, 262, 584, 1021, 318, 635, 12661, 290, 7187, 11, 475, 339, 3769, 3131, 11776, 13, 50655], "temperature": 0.0, "avg_logprob": -0.18152323223295666, "compression_ratio": 1.7553191489361701, "no_speech_prob": 0.0036788543220609426}, {"id": 17, "seek": 5520, "start": 61.040000000000006, "end": 66.44, "text": " For example, if a customer is ordering naan and Indian curry and if the weather is cold", "tokens": [50655, 1114, 1672, 11, 611, 257, 6491, 318, 16216, 12385, 272, 290, 3942, 34611, 290, 611, 262, 6193, 318, 4692, 50925], "temperature": 0.0, "avg_logprob": -0.18152323223295666, "compression_ratio": 1.7553191489361701, "no_speech_prob": 0.0036788543220609426}, {"id": 18, "seek": 5520, "start": 66.44, "end": 71.84, "text": " outside, a Madhu will say, why don't you order this hot tomato soup?", "tokens": [50925, 2354, 11, 257, 4627, 13415, 481, 910, 11, 1521, 836, 470, 345, 1502, 428, 3024, 24240, 17141, 30, 51195], "temperature": 0.0, "avg_logprob": -0.18152323223295666, "compression_ratio": 1.7553191489361701, "no_speech_prob": 0.0036788543220609426}, {"id": 19, "seek": 5520, "start": 71.84, "end": 75.24000000000001, "text": " The weather is cold outside and it will really go well with this dish.", "tokens": [51195, 383, 6193, 318, 4692, 2354, 290, 340, 481, 1107, 467, 880, 351, 428, 9433, 13, 51365], "temperature": 0.0, "avg_logprob": -0.18152323223295666, "compression_ratio": 1.7553191489361701, "no_speech_prob": 0.0036788543220609426}, {"id": 20, "seek": 5520, "start": 75.24000000000001, "end": 80.68, "text": " If the customer is coming again and again, Madhu will recognize their favorite dish and", "tokens": [51365, 1002, 262, 6491, 318, 2406, 757, 290, 757, 11, 4627, 13415, 481, 7564, 511, 4004, 9433, 290, 51637], "temperature": 0.0, "avg_logprob": -0.18152323223295666, "compression_ratio": 1.7553191489361701, "no_speech_prob": 0.0036788543220609426}, {"id": 21, "seek": 5520, "start": 80.68, "end": 85.2, "text": " they will say, oh, last time you order Hara Bara Kebab, would you like to repeat that?", "tokens": [51637, 484, 481, 910, 11, 11752, 11, 938, 640, 345, 1502, 2113, 64, 2409, 64, 509, 1765, 397, 11, 561, 345, 588, 284, 9585, 326, 30, 51863], "temperature": 0.0, "avg_logprob": -0.18152323223295666, "compression_ratio": 1.7553191489361701, "no_speech_prob": 0.0036788543220609426}, {"id": 22, "seek": 8520, "start": 85.2, "end": 88.64, "text": " So this way Madhu is going one step ahead.", "tokens": [50363, 1406, 428, 835, 4627, 13415, 318, 1016, 530, 2239, 4058, 13, 50535], "temperature": 0.0, "avg_logprob": -0.11199920582321454, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.00159073481336236}, {"id": 23, "seek": 8520, "start": 88.64, "end": 90.8, "text": " He's an independent thinker.", "tokens": [50535, 679, 338, 281, 4795, 45206, 13, 50643], "temperature": 0.0, "avg_logprob": -0.11199920582321454, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.00159073481336236}, {"id": 24, "seek": 8520, "start": 90.8, "end": 95.72, "text": " He's providing these suggestions and he's autonomous in the way that he works.", "tokens": [50643, 679, 338, 4955, 777, 11776, 290, 339, 338, 18284, 287, 262, 835, 326, 339, 2499, 13, 50889], "temperature": 0.0, "avg_logprob": -0.11199920582321454, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.00159073481336236}, {"id": 25, "seek": 8520, "start": 95.72, "end": 100.0, "text": " The first waiter Mohan on the other hand is not autonomous.", "tokens": [50889, 383, 717, 46612, 9719, 272, 319, 262, 584, 1021, 318, 407, 18284, 13, 51103], "temperature": 0.0, "avg_logprob": -0.11199920582321454, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.00159073481336236}, {"id": 26, "seek": 8520, "start": 100.0, "end": 101.96000000000001, "text": " He will do things as directed.", "tokens": [51103, 679, 481, 466, 1243, 355, 7924, 13, 51201], "temperature": 0.0, "avg_logprob": -0.11199920582321454, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.00159073481336236}, {"id": 27, "seek": 8520, "start": 101.96000000000001, "end": 107.36, "text": " In this analogy, the second waiter Madhu is an AI agent.", "tokens": [51201, 554, 428, 23970, 11, 262, 1218, 46612, 4627, 13415, 318, 281, 9552, 5797, 13, 51471], "temperature": 0.0, "avg_logprob": -0.11199920582321454, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.00159073481336236}, {"id": 28, "seek": 8520, "start": 107.36, "end": 111.76, "text": " The first waiter Mohan is a traditional AI system.", "tokens": [51471, 383, 717, 46612, 9719, 272, 318, 257, 4569, 9552, 1080, 13, 51691], "temperature": 0.0, "avg_logprob": -0.11199920582321454, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.00159073481336236}, {"id": 29, "seek": 8520, "start": 111.76, "end": 112.76, "text": " Okay.", "tokens": [51691, 16805, 13, 51741], "temperature": 0.0, "avg_logprob": -0.11199920582321454, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.00159073481336236}, {"id": 30, "seek": 8520, "start": 112.76, "end": 114.38, "text": " So both are AI system.", "tokens": [51741, 1406, 1111, 389, 9552, 1080, 13, 51822], "temperature": 0.0, "avg_logprob": -0.11199920582321454, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.00159073481336236}, {"id": 31, "seek": 11438, "start": 114.38, "end": 116.61999999999999, "text": " The first one is a traditional AI system.", "tokens": [50363, 383, 717, 530, 318, 257, 4569, 9552, 1080, 13, 50475], "temperature": 0.0, "avg_logprob": -0.19983472050847234, "compression_ratio": 1.7137096774193548, "no_speech_prob": 0.006949278991669416}, {"id": 32, "seek": 11438, "start": 116.61999999999999, "end": 120.82, "text": " The second one is an AI system, which is based on AI agent.", "tokens": [50475, 383, 1218, 530, 318, 281, 9552, 1080, 11, 543, 318, 1912, 319, 9552, 5797, 13, 50685], "temperature": 0.0, "avg_logprob": -0.19983472050847234, "compression_ratio": 1.7137096774193548, "no_speech_prob": 0.006949278991669416}, {"id": 33, "seek": 11438, "start": 120.82, "end": 125.75999999999999, "text": " Here I have the example of a regular chat board where you ask questions such as what", "tokens": [50685, 3423, 314, 423, 262, 1672, 286, 257, 3218, 8537, 3096, 810, 345, 1265, 2683, 884, 355, 644, 50932], "temperature": 0.0, "avg_logprob": -0.19983472050847234, "compression_ratio": 1.7137096774193548, "no_speech_prob": 0.006949278991669416}, {"id": 34, "seek": 11438, "start": 125.75999999999999, "end": 127.5, "text": " are your store hours?", "tokens": [50932, 389, 534, 3650, 2250, 30, 51019], "temperature": 0.0, "avg_logprob": -0.19983472050847234, "compression_ratio": 1.7137096774193548, "no_speech_prob": 0.006949278991669416}, {"id": 35, "seek": 11438, "start": 127.5, "end": 129.62, "text": " What pizza options do you have?", "tokens": [51019, 1867, 14256, 3689, 466, 345, 423, 30, 51125], "temperature": 0.0, "avg_logprob": -0.19983472050847234, "compression_ratio": 1.7137096774193548, "no_speech_prob": 0.006949278991669416}, {"id": 36, "seek": 11438, "start": 129.62, "end": 131.48, "text": " You can also place an order.", "tokens": [51125, 921, 460, 635, 1295, 281, 1502, 13, 51218], "temperature": 0.0, "avg_logprob": -0.19983472050847234, "compression_ratio": 1.7137096774193548, "no_speech_prob": 0.006949278991669416}, {"id": 37, "seek": 11438, "start": 131.48, "end": 136.88, "text": " This kind of chat board can be easily built using frameworks such as dialog flow, Rasa.", "tokens": [51218, 770, 1611, 286, 8537, 3096, 460, 307, 3538, 3170, 1262, 29251, 884, 355, 17310, 5202, 11, 371, 15462, 13, 51488], "temperature": 0.0, "avg_logprob": -0.19983472050847234, "compression_ratio": 1.7137096774193548, "no_speech_prob": 0.006949278991669416}, {"id": 38, "seek": 11438, "start": 136.88, "end": 142.42, "text": " There are LLM based frameworks to AI agent based chat board system.", "tokens": [51488, 1318, 389, 27140, 44, 1912, 29251, 284, 9552, 5797, 1912, 8537, 3096, 1080, 13, 51765], "temperature": 0.0, "avg_logprob": -0.19983472050847234, "compression_ratio": 1.7137096774193548, "no_speech_prob": 0.006949278991669416}, {"id": 39, "seek": 14242, "start": 142.42, "end": 147.82, "text": " On the other hand, will be autonomous in certain decision making.", "tokens": [50363, 1550, 262, 584, 1021, 11, 481, 307, 18284, 287, 1728, 2551, 1642, 13, 50633], "temperature": 0.0, "avg_logprob": -0.1780248551141648, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.18837407231330872}, {"id": 40, "seek": 14242, "start": 147.82, "end": 153.79999999999998, "text": " For example, you're visiting this pizza store Pandeji pizza store every Friday evening and", "tokens": [50633, 1114, 1672, 11, 345, 821, 10013, 428, 14256, 3650, 16492, 68, 7285, 14256, 3650, 790, 3217, 6180, 290, 50932], "temperature": 0.0, "avg_logprob": -0.1780248551141648, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.18837407231330872}, {"id": 41, "seek": 14242, "start": 153.79999999999998, "end": 158.6, "text": " you're ordering same large veggie pizza with olive topping.", "tokens": [50932, 345, 821, 16216, 976, 1588, 1569, 23571, 14256, 351, 19450, 34366, 13, 51172], "temperature": 0.0, "avg_logprob": -0.1780248551141648, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.18837407231330872}, {"id": 42, "seek": 14242, "start": 158.6, "end": 160.73999999999998, "text": " This chat board can learn from it.", "tokens": [51172, 770, 8537, 3096, 460, 2193, 422, 340, 13, 51279], "temperature": 0.0, "avg_logprob": -0.1780248551141648, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.18837407231330872}, {"id": 43, "seek": 14242, "start": 160.73999999999998, "end": 164.7, "text": " And when you say I want to place an order, it can look at your history and say, Hey,", "tokens": [51279, 843, 618, 345, 910, 314, 765, 284, 1295, 281, 1502, 11, 340, 460, 804, 379, 534, 2106, 290, 910, 11, 14690, 11, 51477], "temperature": 0.0, "avg_logprob": -0.1780248551141648, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.18837407231330872}, {"id": 44, "seek": 14242, "start": 164.7, "end": 168.73999999999998, "text": " would you like to reorder your usual large pizza?", "tokens": [51477, 561, 345, 588, 284, 302, 2875, 534, 6678, 1588, 14256, 30, 51679], "temperature": 0.0, "avg_logprob": -0.1780248551141648, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.18837407231330872}, {"id": 45, "seek": 14242, "start": 168.73999999999998, "end": 169.98, "text": " You'll say yes.", "tokens": [51679, 921, 1183, 910, 3763, 13, 51741], "temperature": 0.0, "avg_logprob": -0.1780248551141648, "compression_ratio": 1.5826771653543308, "no_speech_prob": 0.18837407231330872}, {"id": 46, "seek": 16998, "start": 169.98, "end": 172.48, "text": " It will also have awareness about environment.", "tokens": [50363, 632, 481, 635, 423, 9359, 546, 2858, 13, 50488], "temperature": 0.0, "avg_logprob": -0.1039505909229147, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.02774410881102085}, {"id": 47, "seek": 16998, "start": 172.48, "end": 175.14, "text": " So here it is saying, Hey, it's cold out there.", "tokens": [50488, 1406, 994, 340, 318, 2282, 11, 14690, 11, 340, 338, 4692, 503, 612, 13, 50621], "temperature": 0.0, "avg_logprob": -0.1039505909229147, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.02774410881102085}, {"id": 48, "seek": 16998, "start": 175.14, "end": 178.0, "text": " Do you want to add hot chocolate?", "tokens": [50621, 2141, 345, 765, 284, 751, 3024, 11311, 30, 50764], "temperature": 0.0, "avg_logprob": -0.1039505909229147, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.02774410881102085}, {"id": 49, "seek": 16998, "start": 178.0, "end": 184.98, "text": " So all these suggestions that it is providing, they are not coded into your Python program.", "tokens": [50764, 1406, 477, 777, 11776, 326, 340, 318, 4955, 11, 484, 389, 407, 30817, 656, 534, 11361, 1430, 13, 51113], "temperature": 0.0, "avg_logprob": -0.1039505909229147, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.02774410881102085}, {"id": 50, "seek": 16998, "start": 184.98, "end": 188.98, "text": " This is something that this agent is coming up on its own.", "tokens": [51113, 770, 318, 1223, 326, 428, 5797, 318, 2406, 510, 319, 663, 898, 13, 51313], "temperature": 0.0, "avg_logprob": -0.1039505909229147, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.02774410881102085}, {"id": 51, "seek": 16998, "start": 188.98, "end": 193.6, "text": " It can also check weather and traffic condition and say, Hey, you want to order a pizza, but", "tokens": [51313, 632, 460, 635, 2198, 6193, 290, 4979, 4006, 290, 910, 11, 14690, 11, 345, 765, 284, 1502, 257, 14256, 11, 475, 51544], "temperature": 0.0, "avg_logprob": -0.1039505909229147, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.02774410881102085}, {"id": 52, "seek": 16998, "start": 193.6, "end": 197.85999999999999, "text": " there is a snowstorm and deliveries might be delayed.", "tokens": [51544, 612, 318, 257, 6729, 12135, 290, 31167, 1244, 307, 11038, 13, 51757], "temperature": 0.0, "avg_logprob": -0.1039505909229147, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.02774410881102085}, {"id": 53, "seek": 16998, "start": 197.85999999999999, "end": 198.85999999999999, "text": " This is like human.", "tokens": [51757, 770, 318, 588, 1692, 13, 51807], "temperature": 0.0, "avg_logprob": -0.1039505909229147, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.02774410881102085}, {"id": 54, "seek": 19886, "start": 198.86, "end": 203.74, "text": " If there is a human, he will be aware about environment weather, all of that, and they", "tokens": [50363, 1002, 612, 318, 257, 1692, 11, 339, 481, 307, 3910, 546, 2858, 6193, 11, 477, 286, 326, 11, 290, 484, 50607], "temperature": 0.0, "avg_logprob": -0.21405487872184592, "compression_ratio": 1.546938775510204, "no_speech_prob": 0.07823089510202408}, {"id": 55, "seek": 19886, "start": 203.74, "end": 206.16000000000003, "text": " will provide extra suggestions.", "tokens": [50607, 481, 2148, 3131, 11776, 13, 50728], "temperature": 0.0, "avg_logprob": -0.21405487872184592, "compression_ratio": 1.546938775510204, "no_speech_prob": 0.07823089510202408}, {"id": 56, "seek": 19886, "start": 206.16000000000003, "end": 212.26000000000002, "text": " Now let's understand a little more in technical details, how regular AI chat board works.", "tokens": [50728, 2735, 1309, 338, 1833, 257, 1310, 517, 287, 6276, 3307, 11, 703, 3218, 9552, 8537, 3096, 2499, 13, 51033], "temperature": 0.0, "avg_logprob": -0.21405487872184592, "compression_ratio": 1.546938775510204, "no_speech_prob": 0.07823089510202408}, {"id": 57, "seek": 19886, "start": 212.26000000000002, "end": 217.46, "text": " Whenever you are asking any question, it will first identify an intent.", "tokens": [51033, 21326, 345, 389, 4737, 597, 1808, 11, 340, 481, 717, 5911, 281, 6824, 13, 51293], "temperature": 0.0, "avg_logprob": -0.21405487872184592, "compression_ratio": 1.546938775510204, "no_speech_prob": 0.07823089510202408}, {"id": 58, "seek": 19886, "start": 217.46, "end": 222.34, "text": " So let's say in my chat board, I have three type of intent, general inquiry, placing order", "tokens": [51293, 1406, 1309, 338, 910, 287, 616, 8537, 3096, 11, 314, 423, 1115, 2099, 286, 6824, 11, 2276, 12069, 11, 12560, 1502, 51537], "temperature": 0.0, "avg_logprob": -0.21405487872184592, "compression_ratio": 1.546938775510204, "no_speech_prob": 0.07823089510202408}, {"id": 59, "seek": 19886, "start": 222.34, "end": 223.34, "text": " refund.", "tokens": [51537, 12929, 13, 51587], "temperature": 0.0, "avg_logprob": -0.21405487872184592, "compression_ratio": 1.546938775510204, "no_speech_prob": 0.07823089510202408}, {"id": 60, "seek": 22334, "start": 223.34, "end": 229.88, "text": " Based on the question, it will say, Hey, this is a general inquiry intent.", "tokens": [50363, 13403, 319, 262, 1808, 11, 340, 481, 910, 11, 14690, 11, 428, 318, 257, 2276, 12069, 6824, 13, 50690], "temperature": 0.0, "avg_logprob": -0.10556272537477555, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.4777081608772278}, {"id": 61, "seek": 22334, "start": 229.88, "end": 234.52, "text": " Now you will be like, okay, you can just do exit sentence matching.", "tokens": [50690, 2735, 345, 481, 307, 588, 11, 8788, 11, 345, 460, 655, 466, 8420, 6827, 12336, 13, 50922], "temperature": 0.0, "avg_logprob": -0.10556272537477555, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.4777081608772278}, {"id": 62, "seek": 22334, "start": 234.52, "end": 239.58, "text": " And you can say, this is a software program varies AI, but this is an AI based system", "tokens": [50922, 843, 345, 460, 910, 11, 428, 318, 257, 3788, 1430, 17806, 9552, 11, 475, 428, 318, 281, 9552, 1912, 1080, 51175], "temperature": 0.0, "avg_logprob": -0.10556272537477555, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.4777081608772278}, {"id": 63, "seek": 22334, "start": 239.58, "end": 243.9, "text": " because your question might be different instead of saying, what are your store hours?", "tokens": [51175, 780, 534, 1808, 1244, 307, 1180, 2427, 286, 2282, 11, 644, 389, 534, 3650, 2250, 30, 51391], "temperature": 0.0, "avg_logprob": -0.10556272537477555, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.4777081608772278}, {"id": 64, "seek": 22334, "start": 243.9, "end": 246.76, "text": " You can say, Hey, can you tell me when the store is open?", "tokens": [51391, 921, 460, 910, 11, 14690, 11, 460, 345, 1560, 502, 618, 262, 3650, 318, 1280, 30, 51534], "temperature": 0.0, "avg_logprob": -0.10556272537477555, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.4777081608772278}, {"id": 65, "seek": 22334, "start": 246.76, "end": 248.86, "text": " So there is no exit word to word matching.", "tokens": [51534, 1406, 612, 318, 645, 8420, 1573, 284, 1573, 12336, 13, 51639], "temperature": 0.0, "avg_logprob": -0.10556272537477555, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.4777081608772278}, {"id": 66, "seek": 22334, "start": 248.86, "end": 251.98000000000002, "text": " These two sentences are different, but the meaning is same.", "tokens": [51639, 2312, 734, 13439, 389, 1180, 11, 475, 262, 3616, 318, 976, 13, 51795], "temperature": 0.0, "avg_logprob": -0.10556272537477555, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.4777081608772278}, {"id": 67, "seek": 25198, "start": 251.98, "end": 258.94, "text": " So if you're using any LLM, such as GPT, or cloud, etc, it will be able to match all", "tokens": [50363, 1406, 611, 345, 821, 1262, 597, 27140, 44, 11, 884, 355, 402, 11571, 11, 393, 6279, 11, 3503, 11, 340, 481, 307, 1498, 284, 2872, 477, 50711], "temperature": 0.0, "avg_logprob": -0.15040260922592297, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.021530356258153915}, {"id": 68, "seek": 25198, "start": 258.94, "end": 260.59999999999997, "text": " these sentences, okay?", "tokens": [50711, 777, 13439, 11, 8788, 30, 50794], "temperature": 0.0, "avg_logprob": -0.15040260922592297, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.021530356258153915}, {"id": 69, "seek": 25198, "start": 260.59999999999997, "end": 265.65999999999997, "text": " You can just say that, hey, LLM, if someone asks questions, which is what are your store", "tokens": [50794, 921, 460, 655, 910, 326, 11, 17207, 11, 27140, 44, 11, 611, 2130, 7893, 2683, 11, 543, 318, 644, 389, 534, 3650, 51047], "temperature": 0.0, "avg_logprob": -0.15040260922592297, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.021530356258153915}, {"id": 70, "seek": 25198, "start": 265.65999999999997, "end": 272.3, "text": " hours, or a similar question in English language, then the intent is general inquiry.", "tokens": [51047, 2250, 11, 393, 257, 2092, 1808, 287, 3594, 3303, 11, 788, 262, 6824, 318, 2276, 12069, 13, 51379], "temperature": 0.0, "avg_logprob": -0.15040260922592297, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.021530356258153915}, {"id": 71, "seek": 25198, "start": 272.3, "end": 278.7, "text": " Once you tell that to LLM, next time, if a person asks questions differently, then also", "tokens": [51379, 4874, 345, 1560, 326, 284, 27140, 44, 11, 1306, 640, 11, 611, 257, 1048, 7893, 2683, 10338, 11, 788, 635, 51699], "temperature": 0.0, "avg_logprob": -0.15040260922592297, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.021530356258153915}, {"id": 72, "seek": 25198, "start": 278.7, "end": 281.3, "text": " it will be able to match that intent.", "tokens": [51699, 340, 481, 307, 1498, 284, 2872, 326, 6824, 13, 51829], "temperature": 0.0, "avg_logprob": -0.15040260922592297, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.021530356258153915}, {"id": 73, "seek": 28130, "start": 281.3, "end": 286.12, "text": " A second question you can ask is, can you place an order with large veggie pizza or", "tokens": [50363, 317, 1218, 1808, 345, 460, 1265, 318, 11, 460, 345, 1295, 281, 1502, 351, 1588, 1569, 23571, 14256, 393, 50604], "temperature": 0.0, "avg_logprob": -0.1848991263625968, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.001548881409689784}, {"id": 74, "seek": 28130, "start": 286.12, "end": 291.48, "text": " leaven spinach topping, it will match the intent, say place order, not only that it", "tokens": [50604, 443, 4005, 39129, 34366, 11, 340, 481, 2872, 262, 6824, 11, 910, 1295, 1502, 11, 407, 691, 326, 340, 50872], "temperature": 0.0, "avg_logprob": -0.1848991263625968, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.001548881409689784}, {"id": 75, "seek": 28130, "start": 291.48, "end": 297.1, "text": " will extract the meaningful information, which is what is my order size, my type toppings,", "tokens": [50872, 481, 7925, 262, 11570, 1321, 11, 543, 318, 644, 318, 616, 1502, 2546, 11, 616, 2099, 23126, 654, 11, 51153], "temperature": 0.0, "avg_logprob": -0.1848991263625968, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.001548881409689784}, {"id": 76, "seek": 28130, "start": 297.1, "end": 298.1, "text": " etc.", "tokens": [51153, 3503, 13, 51203], "temperature": 0.0, "avg_logprob": -0.1848991263625968, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.001548881409689784}, {"id": 77, "seek": 28130, "start": 298.1, "end": 303.54, "text": " And it will call an appropriate code or API or let's say Python function, which you can", "tokens": [51203, 843, 340, 481, 869, 281, 5035, 2438, 393, 7824, 393, 1309, 338, 910, 11361, 2163, 11, 543, 345, 460, 51475], "temperature": 0.0, "avg_logprob": -0.1848991263625968, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.001548881409689784}, {"id": 78, "seek": 28130, "start": 303.54, "end": 307.88, "text": " run and place the order and insert a record in database and so on.", "tokens": [51475, 1057, 290, 1295, 262, 1502, 290, 7550, 257, 1700, 287, 6831, 290, 523, 319, 13, 51692], "temperature": 0.0, "avg_logprob": -0.1848991263625968, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.001548881409689784}, {"id": 79, "seek": 28130, "start": 307.88, "end": 309.92, "text": " So this is a traditional chatbot.", "tokens": [51692, 1406, 428, 318, 257, 4569, 8537, 13645, 13, 51794], "temperature": 0.0, "avg_logprob": -0.1848991263625968, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.001548881409689784}, {"id": 80, "seek": 30992, "start": 309.92, "end": 312.3, "text": " This doesn't use any agent, etc.", "tokens": [50363, 770, 1595, 470, 779, 597, 5797, 11, 3503, 13, 50482], "temperature": 0.0, "avg_logprob": -0.13212767061979874, "compression_ratio": 1.772, "no_speech_prob": 0.7416149377822876}, {"id": 81, "seek": 30992, "start": 312.3, "end": 317.24, "text": " If you want to learn more in detail, I have this free YouTube video where I build the", "tokens": [50482, 1002, 345, 765, 284, 2193, 517, 287, 3703, 11, 314, 423, 428, 1479, 7444, 2008, 810, 314, 1382, 262, 50729], "temperature": 0.0, "avg_logprob": -0.13212767061979874, "compression_ratio": 1.772, "no_speech_prob": 0.7416149377822876}, {"id": 82, "seek": 30992, "start": 317.24, "end": 321.0, "text": " exact same chatbot using dialog flow framework.", "tokens": [50729, 2748, 976, 8537, 13645, 1262, 17310, 5202, 9355, 13, 50917], "temperature": 0.0, "avg_logprob": -0.13212767061979874, "compression_ratio": 1.772, "no_speech_prob": 0.7416149377822876}, {"id": 83, "seek": 30992, "start": 321.0, "end": 323.88, "text": " Now let's see how AI agent chatbot will work.", "tokens": [50917, 2735, 1309, 338, 766, 703, 9552, 5797, 8537, 13645, 481, 670, 13, 51061], "temperature": 0.0, "avg_logprob": -0.13212767061979874, "compression_ratio": 1.772, "no_speech_prob": 0.7416149377822876}, {"id": 84, "seek": 30992, "start": 323.88, "end": 330.48, "text": " So first of all, AI agent chatbot will have exact same capabilities as the regular chatbot.", "tokens": [51061, 1406, 717, 286, 477, 11, 9552, 5797, 8537, 13645, 481, 423, 2748, 976, 9889, 355, 262, 3218, 8537, 13645, 13, 51391], "temperature": 0.0, "avg_logprob": -0.13212767061979874, "compression_ratio": 1.772, "no_speech_prob": 0.7416149377822876}, {"id": 85, "seek": 30992, "start": 330.48, "end": 333.84000000000003, "text": " But in addition, it will have extra capabilities.", "tokens": [51391, 887, 287, 3090, 11, 340, 481, 423, 3131, 9889, 13, 51559], "temperature": 0.0, "avg_logprob": -0.13212767061979874, "compression_ratio": 1.772, "no_speech_prob": 0.7416149377822876}, {"id": 86, "seek": 30992, "start": 333.84000000000003, "end": 337.92, "text": " So when you give a sentence, it will be able to identify the intent, it will extract the", "tokens": [51559, 1406, 618, 345, 1577, 257, 6827, 11, 340, 481, 307, 1498, 284, 5911, 262, 6824, 11, 340, 481, 7925, 262, 51763], "temperature": 0.0, "avg_logprob": -0.13212767061979874, "compression_ratio": 1.772, "no_speech_prob": 0.7416149377822876}, {"id": 87, "seek": 33792, "start": 337.92, "end": 341.8, "text": " information, call the Python function API and so on.", "tokens": [50363, 1321, 11, 869, 262, 11361, 2163, 7824, 290, 523, 319, 13, 50557], "temperature": 0.0, "avg_logprob": -0.152537039990695, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.9452140927314758}, {"id": 88, "seek": 33792, "start": 341.8, "end": 347.08000000000004, "text": " But in addition, it will have access to something called tools.", "tokens": [50557, 887, 287, 3090, 11, 340, 481, 423, 1895, 284, 1223, 1444, 4899, 13, 50821], "temperature": 0.0, "avg_logprob": -0.152537039990695, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.9452140927314758}, {"id": 89, "seek": 33792, "start": 347.08000000000004, "end": 351.12, "text": " Now when I say tools, let's say weather API is one type of tool.", "tokens": [50821, 2735, 618, 314, 910, 4899, 11, 1309, 338, 910, 6193, 7824, 318, 530, 2099, 286, 2891, 13, 51023], "temperature": 0.0, "avg_logprob": -0.152537039990695, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.9452140927314758}, {"id": 90, "seek": 33792, "start": 351.12, "end": 357.04, "text": " So it will go check weather API and say there is a snowstorm and you know, there is a traffic", "tokens": [51023, 1406, 340, 481, 467, 2198, 6193, 7824, 290, 910, 612, 318, 257, 6729, 12135, 290, 345, 760, 11, 612, 318, 257, 4979, 51319], "temperature": 0.0, "avg_logprob": -0.152537039990695, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.9452140927314758}, {"id": 91, "seek": 33792, "start": 357.04, "end": 360.28000000000003, "text": " deliveries are delayed, then it will give you this kind of response.", "tokens": [51319, 31167, 389, 11038, 11, 788, 340, 481, 1577, 345, 428, 1611, 286, 2882, 13, 51481], "temperature": 0.0, "avg_logprob": -0.152537039990695, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.9452140927314758}, {"id": 92, "seek": 33792, "start": 360.28000000000003, "end": 365.24, "text": " It will say, hey, due to snowstorm deliveries might be delayed.", "tokens": [51481, 632, 481, 910, 11, 17207, 11, 2233, 284, 6729, 12135, 31167, 1244, 307, 11038, 13, 51729], "temperature": 0.0, "avg_logprob": -0.152537039990695, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.9452140927314758}, {"id": 93, "seek": 36524, "start": 365.24, "end": 369.6, "text": " It may have access to another tool such as a database.", "tokens": [50363, 632, 743, 423, 1895, 284, 1194, 2891, 884, 355, 257, 6831, 13, 50581], "temperature": 0.0, "avg_logprob": -0.18715341212385792, "compression_ratio": 1.6254416961130742, "no_speech_prob": 0.21174921095371246}, {"id": 94, "seek": 36524, "start": 369.6, "end": 372.68, "text": " Database contains all the past records from the same customer.", "tokens": [50581, 24047, 4909, 477, 262, 1613, 4406, 422, 262, 976, 6491, 13, 50735], "temperature": 0.0, "avg_logprob": -0.18715341212385792, "compression_ratio": 1.6254416961130742, "no_speech_prob": 0.21174921095371246}, {"id": 95, "seek": 36524, "start": 372.68, "end": 378.0, "text": " Now you can figure out that this customer is ordering same pizza every Friday at 7 p.m.", "tokens": [50735, 2735, 345, 460, 3785, 503, 326, 428, 6491, 318, 16216, 976, 14256, 790, 3217, 379, 767, 279, 13, 76, 13, 51001], "temperature": 0.0, "avg_logprob": -0.18715341212385792, "compression_ratio": 1.6254416961130742, "no_speech_prob": 0.21174921095371246}, {"id": 96, "seek": 36524, "start": 378.0, "end": 379.12, "text": " or evening.", "tokens": [51001, 393, 6180, 13, 51057], "temperature": 0.0, "avg_logprob": -0.18715341212385792, "compression_ratio": 1.6254416961130742, "no_speech_prob": 0.21174921095371246}, {"id": 97, "seek": 36524, "start": 379.12, "end": 383.0, "text": " Then you will say, hey, would you like to reorder your usual large pizza with olive", "tokens": [51057, 3244, 345, 481, 910, 11, 17207, 11, 561, 345, 588, 284, 302, 2875, 534, 6678, 1588, 14256, 351, 19450, 51251], "temperature": 0.0, "avg_logprob": -0.18715341212385792, "compression_ratio": 1.6254416961130742, "no_speech_prob": 0.21174921095371246}, {"id": 98, "seek": 36524, "start": 383.0, "end": 384.0, "text": " toppings?", "tokens": [51251, 23126, 654, 30, 51301], "temperature": 0.0, "avg_logprob": -0.18715341212385792, "compression_ratio": 1.6254416961130742, "no_speech_prob": 0.21174921095371246}, {"id": 99, "seek": 36524, "start": 384.0, "end": 387.84000000000003, "text": " So see, this is intelligent and autonomous in your code.", "tokens": [51301, 1406, 766, 11, 428, 318, 12661, 290, 18284, 287, 534, 2438, 13, 51493], "temperature": 0.0, "avg_logprob": -0.18715341212385792, "compression_ratio": 1.6254416961130742, "no_speech_prob": 0.21174921095371246}, {"id": 100, "seek": 36524, "start": 387.84000000000003, "end": 393.8, "text": " You're not return that when person says place an order, you should give this as a response.", "tokens": [51493, 921, 821, 407, 1441, 326, 618, 1048, 1139, 1295, 281, 1502, 11, 345, 815, 1577, 428, 355, 257, 2882, 13, 51791], "temperature": 0.0, "avg_logprob": -0.18715341212385792, "compression_ratio": 1.6254416961130742, "no_speech_prob": 0.21174921095371246}, {"id": 101, "seek": 39380, "start": 393.8, "end": 399.32, "text": " OK, in your code, you have not written that, but the agent figures this thing out on his", "tokens": [50363, 7477, 11, 287, 534, 2438, 11, 345, 423, 407, 3194, 326, 11, 475, 262, 5797, 5538, 428, 1517, 503, 319, 465, 50639], "temperature": 0.0, "avg_logprob": -0.16184708412657392, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.10772144049406052}, {"id": 102, "seek": 39380, "start": 399.32, "end": 402.02000000000004, "text": " own and provides suggestion.", "tokens": [50639, 898, 290, 3769, 13052, 13, 50774], "temperature": 0.0, "avg_logprob": -0.16184708412657392, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.10772144049406052}, {"id": 103, "seek": 39380, "start": 402.02000000000004, "end": 404.54, "text": " It can have access to web search.", "tokens": [50774, 632, 460, 423, 1895, 284, 3992, 2989, 13, 50900], "temperature": 0.0, "avg_logprob": -0.16184708412657392, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.10772144049406052}, {"id": 104, "seek": 39380, "start": 404.54, "end": 407.36, "text": " It can have access to a variety of APIs.", "tokens": [50900, 632, 460, 423, 1895, 284, 257, 4996, 286, 23113, 13, 51041], "temperature": 0.0, "avg_logprob": -0.16184708412657392, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.10772144049406052}, {"id": 105, "seek": 39380, "start": 407.36, "end": 413.8, "text": " So these tools are something that you can define when you are writing code for agent.", "tokens": [51041, 1406, 777, 4899, 389, 1223, 326, 345, 460, 8160, 618, 345, 389, 3597, 2438, 329, 5797, 13, 51363], "temperature": 0.0, "avg_logprob": -0.16184708412657392, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.10772144049406052}, {"id": 106, "seek": 39380, "start": 413.8, "end": 419.92, "text": " So agent solution is something for which you have to write code, obviously, but you don't", "tokens": [51363, 1406, 5797, 4610, 318, 1223, 329, 543, 345, 423, 284, 3551, 2438, 11, 6189, 11, 475, 345, 836, 470, 51669], "temperature": 0.0, "avg_logprob": -0.16184708412657392, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.10772144049406052}, {"id": 107, "seek": 41992, "start": 419.92, "end": 425.22, "text": " type all this instruction that if person places an order in a person has a same history", "tokens": [50363, 2099, 477, 428, 12064, 326, 611, 1048, 4113, 281, 1502, 287, 257, 1048, 468, 257, 976, 2106, 50628], "temperature": 0.0, "avg_logprob": -0.19759750366210938, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.7113076448440552}, {"id": 108, "seek": 41992, "start": 425.22, "end": 428.6, "text": " Friday 7 p.m. large veggie, then just repeat that.", "tokens": [50628, 3217, 767, 279, 13, 76, 13, 1588, 1569, 23571, 11, 788, 655, 9585, 326, 13, 50797], "temperature": 0.0, "avg_logprob": -0.19759750366210938, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.7113076448440552}, {"id": 109, "seek": 41992, "start": 428.6, "end": 431.6, "text": " OK, you are just providing all these tools, everything.", "tokens": [50797, 7477, 11, 345, 389, 655, 4955, 477, 777, 4899, 11, 2279, 13, 50947], "temperature": 0.0, "avg_logprob": -0.19759750366210938, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.7113076448440552}, {"id": 110, "seek": 41992, "start": 431.6, "end": 436.96000000000004, "text": " And this suggestion is something that this agent comes up on its own.", "tokens": [50947, 843, 428, 13052, 318, 1223, 326, 428, 5797, 2058, 510, 319, 663, 898, 13, 51215], "temperature": 0.0, "avg_logprob": -0.19759750366210938, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.7113076448440552}, {"id": 111, "seek": 41992, "start": 436.96000000000004, "end": 442.70000000000005, "text": " I give an example of an AI chat board, but there are a variety of solutions that can", "tokens": [51215, 314, 1577, 281, 1672, 286, 281, 9552, 8537, 3096, 11, 475, 612, 389, 257, 4996, 286, 8136, 326, 460, 51502], "temperature": 0.0, "avg_logprob": -0.19759750366210938, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.7113076448440552}, {"id": 112, "seek": 41992, "start": 442.70000000000005, "end": 446.44, "text": " be a recommendation engine that can be a document search.", "tokens": [51502, 307, 257, 15602, 3113, 326, 460, 307, 257, 3188, 2989, 13, 51689], "temperature": 0.0, "avg_logprob": -0.19759750366210938, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.7113076448440552}, {"id": 113, "seek": 41992, "start": 446.44, "end": 449.72, "text": " You know, you can build a variety of solutions.", "tokens": [51689, 921, 760, 11, 345, 460, 1382, 257, 4996, 286, 8136, 13, 51853], "temperature": 0.0, "avg_logprob": -0.19759750366210938, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.7113076448440552}, {"id": 114, "seek": 44972, "start": 449.72, "end": 454.5, "text": " Chat board is just one category of AI solutions to summarize.", "tokens": [50363, 24101, 3096, 318, 655, 530, 6536, 286, 9552, 8136, 284, 35743, 13, 50602], "temperature": 0.0, "avg_logprob": -0.16276884078979492, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.01923065073788166}, {"id": 115, "seek": 44972, "start": 454.5, "end": 459.88000000000005, "text": " The main thing in AI agent is autonomy, independent thinking.", "tokens": [50602, 383, 1388, 1517, 287, 9552, 5797, 318, 21851, 11, 4795, 3612, 13, 50871], "temperature": 0.0, "avg_logprob": -0.16276884078979492, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.01923065073788166}, {"id": 116, "seek": 44972, "start": 459.88000000000005, "end": 463.58000000000004, "text": " Obviously, there will be some limitations on autonomy.", "tokens": [50871, 16263, 11, 612, 481, 307, 617, 11247, 319, 21851, 13, 51056], "temperature": 0.0, "avg_logprob": -0.16276884078979492, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.01923065073788166}, {"id": 117, "seek": 44972, "start": 463.58000000000004, "end": 467.88000000000005, "text": " Your chat board cannot say, hey, I will place your order for free and your family and friends.", "tokens": [51056, 3406, 8537, 3096, 2314, 910, 11, 17207, 11, 314, 481, 1295, 534, 1502, 329, 1479, 290, 534, 1641, 290, 2460, 13, 51271], "temperature": 0.0, "avg_logprob": -0.16276884078979492, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.01923065073788166}, {"id": 118, "seek": 44972, "start": 467.88000000000005, "end": 469.72, "text": " I will give everything for free.", "tokens": [51271, 314, 481, 1577, 2279, 329, 1479, 13, 51363], "temperature": 0.0, "avg_logprob": -0.16276884078979492, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.01923065073788166}, {"id": 119, "seek": 44972, "start": 469.72, "end": 473.16, "text": " That kind of autonomy you can't give to the agents.", "tokens": [51363, 1320, 1611, 286, 21851, 345, 460, 470, 1577, 284, 262, 6554, 13, 51535], "temperature": 0.0, "avg_logprob": -0.16276884078979492, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.01923065073788166}, {"id": 120, "seek": 44972, "start": 473.16, "end": 478.52000000000004, "text": " So when you are building agents by writing code, you will have some kind of control over", "tokens": [51535, 1406, 618, 345, 389, 2615, 6554, 416, 3597, 2438, 11, 345, 481, 423, 617, 1611, 286, 1630, 625, 51803], "temperature": 0.0, "avg_logprob": -0.16276884078979492, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.01923065073788166}, {"id": 121, "seek": 44972, "start": 478.52000000000004, "end": 479.52000000000004, "text": " it.", "tokens": [51803, 340, 13, 51853], "temperature": 0.0, "avg_logprob": -0.16276884078979492, "compression_ratio": 1.6954887218045114, "no_speech_prob": 0.01923065073788166}, {"id": 122, "seek": 47952, "start": 479.52, "end": 483.85999999999996, "text": " If you cannot control the AI agent will be autonomous.", "tokens": [50363, 1002, 345, 2314, 1630, 262, 9552, 5797, 481, 307, 18284, 13, 50580], "temperature": 0.0, "avg_logprob": -0.17909218194916493, "compression_ratio": 1.8166666666666667, "no_speech_prob": 0.055374521762132645}, {"id": 123, "seek": 47952, "start": 483.85999999999996, "end": 486.68, "text": " It's like your dog and you have a lease, right?", "tokens": [50580, 632, 338, 588, 534, 3290, 290, 345, 423, 257, 15278, 11, 826, 30, 50721], "temperature": 0.0, "avg_logprob": -0.17909218194916493, "compression_ratio": 1.8166666666666667, "no_speech_prob": 0.055374521762132645}, {"id": 124, "seek": 47952, "start": 486.68, "end": 489.84, "text": " So dog can roam around, but you have a lease.", "tokens": [50721, 1406, 3290, 460, 35563, 1088, 11, 475, 345, 423, 257, 15278, 13, 50879], "temperature": 0.0, "avg_logprob": -0.17909218194916493, "compression_ratio": 1.8166666666666667, "no_speech_prob": 0.055374521762132645}, {"id": 125, "seek": 47952, "start": 489.84, "end": 493.58, "text": " So the area where it can go, that area is limited, right?", "tokens": [50879, 1406, 262, 1989, 810, 340, 460, 467, 11, 326, 1989, 318, 3614, 11, 826, 30, 51066], "temperature": 0.0, "avg_logprob": -0.17909218194916493, "compression_ratio": 1.8166666666666667, "no_speech_prob": 0.055374521762132645}, {"id": 126, "seek": 47952, "start": 493.58, "end": 499.84, "text": " Let's say you have a two meter long lease or the string, you know, that you tie at dog's", "tokens": [51066, 3914, 338, 910, 345, 423, 257, 734, 16430, 890, 15278, 393, 262, 4731, 11, 345, 760, 11, 326, 345, 9839, 379, 3290, 338, 51379], "temperature": 0.0, "avg_logprob": -0.17909218194916493, "compression_ratio": 1.8166666666666667, "no_speech_prob": 0.055374521762132645}, {"id": 127, "seek": 47952, "start": 499.84, "end": 500.84, "text": " neck.", "tokens": [51379, 7393, 13, 51429], "temperature": 0.0, "avg_logprob": -0.17909218194916493, "compression_ratio": 1.8166666666666667, "no_speech_prob": 0.055374521762132645}, {"id": 128, "seek": 47952, "start": 500.84, "end": 503.14, "text": " The dog can roam around in that two meter radius.", "tokens": [51429, 383, 3290, 460, 35563, 1088, 287, 326, 734, 16430, 16874, 13, 51544], "temperature": 0.0, "avg_logprob": -0.17909218194916493, "compression_ratio": 1.8166666666666667, "no_speech_prob": 0.055374521762132645}, {"id": 129, "seek": 47952, "start": 503.14, "end": 504.34, "text": " So it is autonomous.", "tokens": [51544, 1406, 340, 318, 18284, 13, 51604], "temperature": 0.0, "avg_logprob": -0.17909218194916493, "compression_ratio": 1.8166666666666667, "no_speech_prob": 0.055374521762132645}, {"id": 130, "seek": 47952, "start": 504.34, "end": 508.4, "text": " But on top of that, there is some control that you're imposing.", "tokens": [51604, 887, 319, 1353, 286, 326, 11, 612, 318, 617, 1630, 326, 345, 821, 20814, 13, 51807], "temperature": 0.0, "avg_logprob": -0.17909218194916493, "compression_ratio": 1.8166666666666667, "no_speech_prob": 0.055374521762132645}, {"id": 131, "seek": 50840, "start": 508.4, "end": 514.72, "text": " There are frameworks such as Langraph, Microsoft autogen, crew AI, etc, that you can use to", "tokens": [50363, 1318, 389, 29251, 884, 355, 16332, 1470, 11, 5413, 1960, 6644, 11, 5462, 9552, 11, 3503, 11, 326, 345, 460, 779, 284, 50679], "temperature": 0.0, "avg_logprob": -0.16331803171258225, "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.7560802698135376}, {"id": 132, "seek": 50840, "start": 514.72, "end": 516.34, "text": " build AI agents.", "tokens": [50679, 1382, 9552, 6554, 13, 50760], "temperature": 0.0, "avg_logprob": -0.16331803171258225, "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.7560802698135376}, {"id": 133, "seek": 50840, "start": 516.34, "end": 520.1999999999999, "text": " I'm going to be publishing more videos on AI agents in the coming time.", "tokens": [50760, 314, 1101, 1016, 284, 307, 12407, 517, 5861, 319, 9552, 6554, 287, 262, 2406, 640, 13, 50953], "temperature": 0.0, "avg_logprob": -0.16331803171258225, "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.7560802698135376}, {"id": 134, "seek": 50840, "start": 520.1999999999999, "end": 522.16, "text": " So please keep an eye.", "tokens": [50953, 1406, 3387, 1394, 281, 4151, 13, 51051], "temperature": 0.0, "avg_logprob": -0.16331803171258225, "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.7560802698135376}, {"id": 135, "seek": 50840, "start": 522.16, "end": 525.8, "text": " And if you like this video, then please give it a thumbs up, share it with your friends.", "tokens": [51051, 843, 611, 345, 588, 428, 2008, 11, 788, 3387, 1577, 340, 257, 32766, 510, 11, 2648, 340, 351, 534, 2460, 13, 51233], "temperature": 0.0, "avg_logprob": -0.16331803171258225, "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.7560802698135376}, {"id": 136, "seek": 50840, "start": 525.8, "end": 528.4, "text": " If you have any comments, there is a comment box below.", "tokens": [51233, 1002, 345, 423, 597, 3651, 11, 612, 318, 257, 2912, 3091, 2174, 13, 51363], "temperature": 0.0, "avg_logprob": -0.16331803171258225, "compression_ratio": 1.5398230088495575, "no_speech_prob": 0.7560802698135376}], "language": "en"}