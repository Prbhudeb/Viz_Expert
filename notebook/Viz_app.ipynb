{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be64ace-04dc-4e01-b2f4-8a8e6ff63d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from ibm_watson import speech_to_text_v1\n",
    "from ibm_watson.websocket import recognize_abstract_callback,audio_source\n",
    "from ibm_cloud_sdk_core.authenticators import iam_authenticator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d388d0f-bf41-45bc-b650-6c0791f397d8",
   "metadata": {},
   "source": [
    "## Extract Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ab2af91-df01-4690-9597-c2be7e9438de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1-3ubuntu5 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 13 (Ubuntu 13.2.0-23ubuntu3)\n",
      "  configuration: --prefix=/usr --extra-version=3ubuntu5 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --disable-omx --enable-gnutls --enable-libaom --enable-libass --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libharfbuzz --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-openal --enable-opencl --enable-opengl --disable-sndio --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-ladspa --enable-libbluray --enable-libjack --enable-libpulse --enable-librabbitmq --enable-librist --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libx264 --enable-libzmq --enable-libzvbi --enable-lv2 --enable-sdl2 --enable-libplacebo --enable-librav1e --enable-pocketsphinx --enable-librsvg --enable-libjxl --enable-shared\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../data/input_video/AI_agent.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    creation_time   : 2024-09-20T07:18:41.000000Z\n",
      "    encoder         : Google\n",
      "  Duration: 00:08:52.55, start: 0.000000, bitrate: 300 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 640x360 [SAR 1:1 DAR 16:9], 169 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-09-20T07:18:41.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/20/2024.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-09-20T07:18:41.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/20/2024.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '../data/extracted_audio/audio.wav':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    ISFT            : Lavf60.16.100\n",
      "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-09-20T07:18:41.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/20/2024.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 pcm_s16le\n",
      "[out#0/wav @ 0x567c8007fc00] video:0kB audio:91740kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000083%\n",
      "size=   91740kB time=00:08:52.52 bitrate=1411.3kbits/s speed= 508x    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = 'ffmpeg -i ../data/input_video/AI_agent.mp4 -ab 160k -ar 44100 -vn ../data/extracted_audio/audio.wav'\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100b1480-98f7-4bd6-8beb-3a3c6cdf8603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [06:23<00:00, 3.98MiB/s]\n",
      "/home/prbhudeb/Desktop/VizExpert/venv/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/home/prbhudeb/Desktop/VizExpert/venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "[00:00.000 --> 00:02.980]  So I think we're going to live in a world where there are going to be hundreds of millions\n",
      "[00:02.980 --> 00:07.800]  of billions of different AI agents, eventually probably more AI agents than there are people\n",
      "[00:07.800 --> 00:08.800]  in the world.\n",
      "[00:08.800 --> 00:13.440]  From generative AI to what's known as agentic AIs.\n",
      "[00:13.440 --> 00:15.960]  That agent force is what he's calling it.\n",
      "[00:15.960 --> 00:16.960]  Agent force will be...\n",
      "[00:16.960 --> 00:22.600]  AI agents has become the talk of the town and today I'm going to explain this concept\n",
      "[00:22.600 --> 00:26.600]  in a way that even a high school student can understand it easily.\n",
      "[00:26.600 --> 00:30.600]  Let's start with analogy and then we will go into technical details.\n",
      "[00:30.600 --> 00:35.040]  Let's say you have a restaurant you hire two waiters, Mohan and Madhu.\n",
      "[00:35.040 --> 00:36.600]  Mohan is intelligent and accurate.\n",
      "[00:36.600 --> 00:41.640]  He will go to a customer who is coming to a restaurant and then he will offer the food\n",
      "[00:41.640 --> 00:42.640]  menu.\n",
      "[00:42.640 --> 00:44.680]  The customer will order few things.\n",
      "[00:44.680 --> 00:49.000]  He will accurately note it down and deliver it in a nice manner.\n",
      "[00:49.000 --> 00:55.200]  While Mohan is accurate in his work, he doesn't provide extra suggestions or recommendation.\n",
      "[00:55.200 --> 01:01.040]  Madhu on the other hand is also intelligent and accurate, but he provides extra suggestions.\n",
      "[01:01.040 --> 01:06.440]  For example, if a customer is ordering naan and Indian curry and if the weather is cold\n",
      "[01:06.440 --> 01:11.840]  outside, a Madhu will say, why don't you order this hot tomato soup?\n",
      "[01:11.840 --> 01:15.240]  The weather is cold outside and it will really go well with this dish.\n",
      "[01:15.240 --> 01:20.680]  If the customer is coming again and again, Madhu will recognize their favorite dish and\n",
      "[01:20.680 --> 01:25.200]  they will say, oh, last time you order Hara Bara Kebab, would you like to repeat that?\n",
      "[01:25.200 --> 01:28.640]  So this way Madhu is going one step ahead.\n",
      "[01:28.640 --> 01:30.800]  He's an independent thinker.\n",
      "[01:30.800 --> 01:35.720]  He's providing these suggestions and he's autonomous in the way that he works.\n",
      "[01:35.720 --> 01:40.000]  The first waiter Mohan on the other hand is not autonomous.\n",
      "[01:40.000 --> 01:41.960]  He will do things as directed.\n",
      "[01:41.960 --> 01:47.360]  In this analogy, the second waiter Madhu is an AI agent.\n",
      "[01:47.360 --> 01:51.760]  The first waiter Mohan is a traditional AI system.\n",
      "[01:51.760 --> 01:52.760]  Okay.\n",
      "[01:52.760 --> 01:54.380]  So both are AI system.\n",
      "[01:54.380 --> 01:56.620]  The first one is a traditional AI system.\n",
      "[01:56.620 --> 02:00.820]  The second one is an AI system, which is based on AI agent.\n",
      "[02:00.820 --> 02:05.760]  Here I have the example of a regular chat board where you ask questions such as what\n",
      "[02:05.760 --> 02:07.500]  are your store hours?\n",
      "[02:07.500 --> 02:09.620]  What pizza options do you have?\n",
      "[02:09.620 --> 02:11.480]  You can also place an order.\n",
      "[02:11.480 --> 02:16.880]  This kind of chat board can be easily built using frameworks such as dialog flow, Rasa.\n",
      "[02:16.880 --> 02:22.420]  There are LLM based frameworks to AI agent based chat board system.\n",
      "[02:22.420 --> 02:27.820]  On the other hand, will be autonomous in certain decision making.\n",
      "[02:27.820 --> 02:33.800]  For example, you're visiting this pizza store Pandeji pizza store every Friday evening and\n",
      "[02:33.800 --> 02:38.600]  you're ordering same large veggie pizza with olive topping.\n",
      "[02:38.600 --> 02:40.740]  This chat board can learn from it.\n",
      "[02:40.740 --> 02:44.700]  And when you say I want to place an order, it can look at your history and say, Hey,\n",
      "[02:44.700 --> 02:48.740]  would you like to reorder your usual large pizza?\n",
      "[02:48.740 --> 02:49.980]  You'll say yes.\n",
      "[02:49.980 --> 02:52.480]  It will also have awareness about environment.\n",
      "[02:52.480 --> 02:55.140]  So here it is saying, Hey, it's cold out there.\n",
      "[02:55.140 --> 02:58.000]  Do you want to add hot chocolate?\n",
      "[02:58.000 --> 03:04.980]  So all these suggestions that it is providing, they are not coded into your Python program.\n",
      "[03:04.980 --> 03:08.980]  This is something that this agent is coming up on its own.\n",
      "[03:08.980 --> 03:13.600]  It can also check weather and traffic condition and say, Hey, you want to order a pizza, but\n",
      "[03:13.600 --> 03:17.860]  there is a snowstorm and deliveries might be delayed.\n",
      "[03:17.860 --> 03:18.860]  This is like human.\n",
      "[03:18.860 --> 03:23.740]  If there is a human, he will be aware about environment weather, all of that, and they\n",
      "[03:23.740 --> 03:26.160]  will provide extra suggestions.\n",
      "[03:26.160 --> 03:32.260]  Now let's understand a little more in technical details, how regular AI chat board works.\n",
      "[03:32.260 --> 03:37.460]  Whenever you are asking any question, it will first identify an intent.\n",
      "[03:37.460 --> 03:42.340]  So let's say in my chat board, I have three type of intent, general inquiry, placing order\n",
      "[03:42.340 --> 03:43.340]  refund.\n",
      "[03:43.340 --> 03:49.880]  Based on the question, it will say, Hey, this is a general inquiry intent.\n",
      "[03:49.880 --> 03:54.520]  Now you will be like, okay, you can just do exit sentence matching.\n",
      "[03:54.520 --> 03:59.580]  And you can say, this is a software program varies AI, but this is an AI based system\n",
      "[03:59.580 --> 04:03.900]  because your question might be different instead of saying, what are your store hours?\n",
      "[04:03.900 --> 04:06.760]  You can say, Hey, can you tell me when the store is open?\n",
      "[04:06.760 --> 04:08.860]  So there is no exit word to word matching.\n",
      "[04:08.860 --> 04:11.980]  These two sentences are different, but the meaning is same.\n",
      "[04:11.980 --> 04:18.940]  So if you're using any LLM, such as GPT, or cloud, etc, it will be able to match all\n",
      "[04:18.940 --> 04:20.600]  these sentences, okay?\n",
      "[04:20.600 --> 04:25.660]  You can just say that, hey, LLM, if someone asks questions, which is what are your store\n",
      "[04:25.660 --> 04:32.300]  hours, or a similar question in English language, then the intent is general inquiry.\n",
      "[04:32.300 --> 04:38.700]  Once you tell that to LLM, next time, if a person asks questions differently, then also\n",
      "[04:38.700 --> 04:41.300]  it will be able to match that intent.\n",
      "[04:41.300 --> 04:46.120]  A second question you can ask is, can you place an order with large veggie pizza or\n",
      "[04:46.120 --> 04:51.480]  leaven spinach topping, it will match the intent, say place order, not only that it\n",
      "[04:51.480 --> 04:57.100]  will extract the meaningful information, which is what is my order size, my type toppings,\n",
      "[04:57.100 --> 04:58.100]  etc.\n",
      "[04:58.100 --> 05:03.540]  And it will call an appropriate code or API or let's say Python function, which you can\n",
      "[05:03.540 --> 05:07.880]  run and place the order and insert a record in database and so on.\n",
      "[05:07.880 --> 05:09.920]  So this is a traditional chatbot.\n",
      "[05:09.920 --> 05:12.300]  This doesn't use any agent, etc.\n",
      "[05:12.300 --> 05:17.240]  If you want to learn more in detail, I have this free YouTube video where I build the\n",
      "[05:17.240 --> 05:21.000]  exact same chatbot using dialog flow framework.\n",
      "[05:21.000 --> 05:23.880]  Now let's see how AI agent chatbot will work.\n",
      "[05:23.880 --> 05:30.480]  So first of all, AI agent chatbot will have exact same capabilities as the regular chatbot.\n",
      "[05:30.480 --> 05:33.840]  But in addition, it will have extra capabilities.\n",
      "[05:33.840 --> 05:37.920]  So when you give a sentence, it will be able to identify the intent, it will extract the\n",
      "[05:37.920 --> 05:41.800]  information, call the Python function API and so on.\n",
      "[05:41.800 --> 05:47.080]  But in addition, it will have access to something called tools.\n",
      "[05:47.080 --> 05:51.120]  Now when I say tools, let's say weather API is one type of tool.\n",
      "[05:51.120 --> 05:57.040]  So it will go check weather API and say there is a snowstorm and you know, there is a traffic\n",
      "[05:57.040 --> 06:00.280]  deliveries are delayed, then it will give you this kind of response.\n",
      "[06:00.280 --> 06:05.240]  It will say, hey, due to snowstorm deliveries might be delayed.\n",
      "[06:05.240 --> 06:09.600]  It may have access to another tool such as a database.\n",
      "[06:09.600 --> 06:12.680]  Database contains all the past records from the same customer.\n",
      "[06:12.680 --> 06:18.000]  Now you can figure out that this customer is ordering same pizza every Friday at 7 p.m.\n",
      "[06:18.000 --> 06:19.120]  or evening.\n",
      "[06:19.120 --> 06:23.000]  Then you will say, hey, would you like to reorder your usual large pizza with olive\n",
      "[06:23.000 --> 06:24.000]  toppings?\n",
      "[06:24.000 --> 06:27.840]  So see, this is intelligent and autonomous in your code.\n",
      "[06:27.840 --> 06:33.800]  You're not return that when person says place an order, you should give this as a response.\n",
      "[06:33.800 --> 06:39.320]  OK, in your code, you have not written that, but the agent figures this thing out on his\n",
      "[06:39.320 --> 06:42.020]  own and provides suggestion.\n",
      "[06:42.020 --> 06:44.540]  It can have access to web search.\n",
      "[06:44.540 --> 06:47.360]  It can have access to a variety of APIs.\n",
      "[06:47.360 --> 06:53.800]  So these tools are something that you can define when you are writing code for agent.\n",
      "[06:53.800 --> 06:59.920]  So agent solution is something for which you have to write code, obviously, but you don't\n",
      "[06:59.920 --> 07:05.220]  type all this instruction that if person places an order in a person has a same history\n",
      "[07:05.220 --> 07:08.600]  Friday 7 p.m. large veggie, then just repeat that.\n",
      "[07:08.600 --> 07:11.600]  OK, you are just providing all these tools, everything.\n",
      "[07:11.600 --> 07:16.960]  And this suggestion is something that this agent comes up on its own.\n",
      "[07:16.960 --> 07:22.700]  I give an example of an AI chat board, but there are a variety of solutions that can\n",
      "[07:22.700 --> 07:26.440]  be a recommendation engine that can be a document search.\n",
      "[07:26.440 --> 07:29.720]  You know, you can build a variety of solutions.\n",
      "[07:29.720 --> 07:34.500]  Chat board is just one category of AI solutions to summarize.\n",
      "[07:34.500 --> 07:39.880]  The main thing in AI agent is autonomy, independent thinking.\n",
      "[07:39.880 --> 07:43.580]  Obviously, there will be some limitations on autonomy.\n",
      "[07:43.580 --> 07:47.880]  Your chat board cannot say, hey, I will place your order for free and your family and friends.\n",
      "[07:47.880 --> 07:49.720]  I will give everything for free.\n",
      "[07:49.720 --> 07:53.160]  That kind of autonomy you can't give to the agents.\n",
      "[07:53.160 --> 07:58.520]  So when you are building agents by writing code, you will have some kind of control over\n",
      "[07:58.520 --> 07:59.520]  it.\n",
      "[07:59.520 --> 08:03.860]  If you cannot control the AI agent will be autonomous.\n",
      "[08:03.860 --> 08:06.680]  It's like your dog and you have a lease, right?\n",
      "[08:06.680 --> 08:09.840]  So dog can roam around, but you have a lease.\n",
      "[08:09.840 --> 08:13.580]  So the area where it can go, that area is limited, right?\n",
      "[08:13.580 --> 08:19.840]  Let's say you have a two meter long lease or the string, you know, that you tie at dog's\n",
      "[08:19.840 --> 08:20.840]  neck.\n",
      "[08:20.840 --> 08:23.140]  The dog can roam around in that two meter radius.\n",
      "[08:23.140 --> 08:24.340]  So it is autonomous.\n",
      "[08:24.340 --> 08:28.400]  But on top of that, there is some control that you're imposing.\n",
      "[08:28.400 --> 08:34.720]  There are frameworks such as Langraph, Microsoft autogen, crew AI, etc, that you can use to\n",
      "[08:34.720 --> 08:36.340]  build AI agents.\n",
      "[08:36.340 --> 08:40.200]  I'm going to be publishing more videos on AI agents in the coming time.\n",
      "[08:40.200 --> 08:42.160]  So please keep an eye.\n",
      "[08:42.160 --> 08:45.800]  And if you like this video, then please give it a thumbs up, share it with your friends.\n",
      "[08:45.800 --> 08:48.400]  If you have any comments, there is a comment box below.\n"
     ]
    }
   ],
   "source": [
    "!whisper \"../data/extracted_audio/audio.wav\" --model medium.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b50b9-bcfc-42ff-a39a-47e360ff3db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
